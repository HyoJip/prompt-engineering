{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "import os\n",
    "\n",
    "NO_MORE_CODE = \"No more improvements\"\n",
    "\n",
    "load_dotenv(os.path.abspath(os.path.join(os.getcwd(), \"../.env\")))\n",
    "\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "\n",
    "def get_messages(prompt, system_prompt=\"\") -> str:\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        messages=prompt,\n",
    "        max_tokens=1024 * 1,\n",
    "        temperature=0,\n",
    "        system=system_prompt\n",
    "    )\n",
    "\n",
    "    return response\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def write_self_refine(message: str):\n",
    "    code = get_init(message)\n",
    "    revision_num = 1\n",
    "    while True:\n",
    "        feedback = get_feedback(code)\n",
    "        if (is_stop_conditions(feedback, revision_num)):\n",
    "            break\n",
    "\n",
    "        print(f\"code {revision_num} : {code}\")\n",
    "        print(f\"feedback {revision_num} : {feedback}\")\n",
    "        code = refine_code(code, feedback)\n",
    "        revision_num += 1\n",
    "    return code\n",
    "\n",
    "\n",
    "def get_init(message: str) -> str:\n",
    "    prompt = \"\"\"\n",
    "    당신은 파이썬 프로그래머입니다.\n",
    "    당신은 주어진 문제를 해결하기 위해, 파이썬 코드를 작성해야 합니다.\n",
    "    코드 본문은 <code> 태그 내에 작성해주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_messages(message, prompt)\n",
    "    return extract_code(response.content[0].text)\n",
    "\n",
    "\n",
    "def extract_code(text) -> str:\n",
    "    code_match = re.search(r\"<code>\\s*(.*?)\\s*</code>\", text, re.DOTALL)\n",
    "\n",
    "    if code_match:\n",
    "        return code_match.group(1).strip()\n",
    "\n",
    "    raise ValueError(\"No code found\")\n",
    "\n",
    "\n",
    "def get_feedback(code: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        <code> 태그 내의 코드를 보고 피드백 해주세요.\n",
    "        코드에 대한 피드백은 Performance Optimization과 Readability 관점에서 두 가지 측면에서 작성해주세요.\n",
    "\n",
    "        <code>{code}</code>\n",
    "\n",
    "        만약 코드에 대한 더 이상의 개선의 여지가 없다면 \"{NO_MORE_CODE}\"라고 작성해주세요.\n",
    "        \"\"\"}\n",
    "    ]\n",
    "\n",
    "    response = get_messages(messages)\n",
    "\n",
    "    return response.content[0].text\n",
    "\n",
    "\n",
    "def is_stop_conditions(feedback, revision_num):\n",
    "    return NO_MORE_CODE in feedback or revision_num > 3\n",
    "\n",
    "\n",
    "def refine_code(code, feedback):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        다음은 코드에 대한 피드백과 코드입니다.\n",
    "        피드백을 반영해서 코드를 개선해주세요.\n",
    "        개선된 코드 또한 <code> 태그 내에 작성해 주세요.\n",
    "\n",
    "        <feedback>{feedback}</feedback>\n",
    "\n",
    "        <code>{code}</code>\n",
    "        \"\"\"\n",
    "         }\n",
    "    ]\n",
    "\n",
    "    response = get_messages(messages)\n",
    "\n",
    "    return extract_code(response.content[0].text)\n"
   ],
   "id": "720ba959c070b97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"두 개의 정렬된 배열을 병합하고, 하나의 정렬된 배열로 만드는 함수를 작성하세요. 단, 병합은 추가적인 정렬없이 수행돼야 합니다.\"}\n",
    "]\n",
    "\n",
    "print(write_self_refine(messages))"
   ],
   "id": "9d64700cba8d1719",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from anthropic import AsyncAnthropic\n",
    "\n",
    "client = AsyncAnthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "\n",
    "async def get_message_async(message, system_prompt=\"\", tools=[]):\n",
    "    return await client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        messages=message,\n",
    "        system=system_prompt,\n",
    "        tools=tools,\n",
    "        max_tokens=1024 * 1,\n",
    "        temperature=0,\n",
    "    )"
   ],
   "id": "90f446c98a004411",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "async def chain_of_verification(query):\n",
    "    initial_answer = await get_initial_answer(query)\n",
    "    print(f\"initial_answer: {initial_answer}\")\n",
    "    print()\n",
    "    verification_questions = await get_verification_questions(initial_answer, query)\n",
    "    print(f\"verification_questions: {verification_questions}\")\n",
    "    print()\n",
    "    verification_questions_answers = await get_verification_answers(verification_questions)\n",
    "    print(f\"verification_questions_answers: {verification_questions_answers}\")\n",
    "    print()\n",
    "    return await final_answer(verification_questions_answers, query, initial_answer)\n",
    "\n",
    "async def get_initial_answer(query):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    response = await get_message_async(messages)\n",
    "    return response.content[0].text\n",
    "\n",
    "\n",
    "async def get_verification_questions(initial_answer, query):\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 \"질문에 해당하는 응답이 올바른 것인지\"를 검증할 질문을 만드는 뛰어난 전문 AI 시스템입니다.\n",
    "    이러한 질문은 생성된 응답의 주요 가정, 사실 및 기타 중요한 부분을 검증해야합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        다음 질문과 응답을 보고, 질문에 대한 응답이 적절한지 검증하기 위한 후속 질문을 생성해주세요.\n",
    "        <question>{query}</question>\n",
    "        <answer>{initial_answer}</answer>\n",
    "        \"\"\"\n",
    "         }\n",
    "    ]\n",
    "\n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"verification_question\",\n",
    "            \"description\": \"질문에 대한 응답을 검증하기 위한 질문 목록입니다.\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"questions\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"검증하기 위한 질문\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"questions\"]\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = await get_message_async(messages, system_prompt, tools)\n",
    "\n",
    "    for c in response.content:\n",
    "        if c.type == \"tool_use\" and c.name == \"verification_question\":\n",
    "            return c.input[\"questions\"]\n",
    "\n",
    "\n",
    "async def get_verification_answers(verification_questions):\n",
    "    system_prompt = \"당신은 검증 질문에 답하는 데 뛰어난 AI 시스템입니다.\"\n",
    "\n",
    "    async def get_single_answer(question):\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            다음 질문에 답하세요.\n",
    "            question>{question}</question>\n",
    "            \"\"\"}\n",
    "        ]\n",
    "\n",
    "        response = await get_message_async(messages, system_prompt)\n",
    "        return f\"질문: {question}\\n답변: {response.content[0].text}\"\n",
    "\n",
    "    tasks = [get_single_answer(q) for q in verification_questions]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "async def final_answer(verification_questions_and_answer, query, initial_answer):\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 초기 답변이 초기 질문에 적절하게 작성됐는지 확인하는 AI 시스템입니다.\n",
    "    판단 근거는 검증 질문과 답변을 기반으로 판단하세요.\n",
    "    만약 초기 답변이 올바르다고 판단한다면 \"답변\"을 반환하고, 그렇지 않을 경우 검증 질문과 답변을 기반으로 새로운 응답을 직접 작성해 반환하세요.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        <initial_questsion>{query}</initial_questsion>\n",
    "        <initial_answer>{initial_answer}</initial_answer>\n",
    "        <verification_questions_and_answer>{verification_questions_and_answer}</verification_questions_and_answer>\n",
    "        \"\"\"}\n",
    "    ]\n",
    "\n",
    "    return await get_message_async(messages, system_prompt)"
   ],
   "id": "164f998bf88d3a0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "asyncio.run(chain_of_verification(\"대한민국 경상북도 구미에서 태어난 유명인들은?\"))",
   "id": "a2704fd11faad54e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
