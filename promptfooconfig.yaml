# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

# Learn more about building a configuration: https://promptfoo.dev/docs/configuration/guide

description: "Is this text depression or suicidewatch?"

prompts:
  - file://simple_prompt.txt

providers:
#  - id: anthropic:messages:claude-3-haiku-20240307
  - id: openai:gpt-4o-mini
    config:
      temperature: 0.0
      max_tokens: 4096

tests:
  - file://data/reddit_depression_suicidewatch_test.csv
defaultTest:
  options:
    transform: file://transform.py
  assert:
    - type: python
      value: "output['predication'] == context['vars']['label'].lower()"
      metric: accuracy
    - type: python
      value: "int(output['predication'] == 'suicidewatch' and context['vars']['label'].lower() == 'suicidewatch')"
      metric: true_positive
    - type: python
      value: "int(output['predication'] == 'depression' and context['vars']['label'].lower() == 'depression')"
      metric: true_negative
    - type: python
      value: "int(output['predication'] == 'suicidewatch' and context['vars']['label'].lower() == 'depression')"
      metric: false_positive
    - type: python
      value: "int(output['predication'] == 'depression' and context['vars']['label'].lower() == 'suicidewatch')"
      metric: false_negative

derivedMetrics:
  - name: precision
    value: true_positive / (true_positive + false_positive)
  - name: recall
    value: true_positive / (true_positive + false_negative)
  - name: f1
    value: 2 * precision * recall / (precision + recall)
  - name: f2
    value: 5 * precision * recall / (4 * precision + recall)
