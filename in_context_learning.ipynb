{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-30T09:56:56.665572Z",
     "start_time": "2025-01-30T09:56:56.655204Z"
    }
   },
   "source": [
    "from re import RegexFlag\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic(\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "def get_messages(prompt):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=2048,\n",
    "        temperature=1,\n",
    "    )\n",
    "    return response.content[0].text"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:57:01.764072Z",
     "start_time": "2025-01-30T09:56:58.938190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class GenericReview(BaseModel):\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "\n",
    "def generate_review(input, sentiment) -> GenericReview:\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant that generates a review based on the input.\n",
    "generate a review based on the input with a sentiment of {sentiment}.\n",
    "\n",
    "{input}\n",
    "\n",
    "the generated review should be enclosed in <review> tags.\n",
    "\"\"\"\n",
    "\n",
    "    response = get_messages(prompt)\n",
    "    review = re.search(r\"<review>(.*?)</review>\", response, RegexFlag.DOTALL).group(1).strip()\n",
    "\n",
    "    return GenericReview(\n",
    "        review=review,\n",
    "        sentiment=sentiment\n",
    "    )\n",
    "\n",
    "generate_review(\"The product is great!\", \"positive\")"
   ],
   "id": "b66b197d38d28b62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericReview(review=\"I absolutely love this product! It's truly exceptional in every way. The quality is outstanding, and it perfectly meets all my needs. I'm thoroughly impressed by how great it is and can't imagine my life without it now. If you're considering buying it, don't hesitate – you won't be disappointed. This product has exceeded all my expectations and then some. It's a game-changer that I wholeheartedly recommend to everyone!\", sentiment='positive')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T10:07:50.875484Z",
     "start_time": "2025-01-30T10:07:26.130359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = \"The product is great!\"\n",
    "samples = [\n",
    "    review\n",
    "    for sentiment in [\"positive\", \"neutral\", \"negative\"]\n",
    "    for _ in range(3)\n",
    "    if (review := generate_review(input, sentiment)) is not None\n",
    "]\n",
    "\n",
    "samples"
   ],
   "id": "d81b1e6afdc99589",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GenericReview(review=\"I absolutely love this product! It's truly fantastic and exceeds all my expectations. The quality is outstanding, and it performs brilliantly in every aspect. I can't say enough good things about how great it is. It's a game-changer that has made a significant positive impact on my daily life. If you're considering buying it, don't hesitate – you won't be disappointed. This product is definitely worth every penny and then some. I'm thoroughly impressed and couldn't be happier with my purchase!\", sentiment='positive'),\n",
       " GenericReview(review=\"tags:\\n\\n<review>\\nI absolutely love this product! It's truly outstanding in every way. The quality is top-notch, and it performs exactly as advertised, if not better. From the moment I started using it, I knew I had made an excellent choice. It's user-friendly, efficient, and has exceeded all my expectations. The design is sleek and modern, making it a pleasure to use. I've already recommended it to friends and family because I'm so impressed. This product has made a significant positive impact on my daily life, and I couldn't be happier with my purchase. It's definitely worth every penny, and I can confidently say it's one of the best investments I've made in a long time. If you're considering buying this, don't hesitate – you won't be disappointed!\", sentiment='positive'),\n",
       " GenericReview(review=\"tags:\\n\\n<review>\\nI couldn't be more thrilled with this product! It truly lives up to its reputation of being great. From the moment I started using it, I was impressed by its quality and performance. The design is sleek and user-friendly, making it a joy to incorporate into my daily routine. It's clear that a lot of thought and care went into creating this item, and it shows in every aspect. Whether you're a first-time user or a long-time fan of similar products, this one stands out from the crowd. I've already recommended it to friends and family, and I'm confident they'll love it just as much as I do. In short, if you're on the fence about purchasing, don't hesitate – this product is absolutely worth every penny!\", sentiment='positive'),\n",
       " GenericReview(review=\"tags:\\n\\n<review>\\nThis product meets expectations. While it has some positive qualities, it may not stand out as exceptional. It performs its intended functions adequately, though there could be room for improvement in certain areas. For those considering this item, it's worth weighing both its strengths and limitations before making a decision. Overall, it's a serviceable option that may suit some users' needs, but others might find alternatives more appealing depending on their specific requirements.\", sentiment='neutral'),\n",
       " GenericReview(review='tags:\\n\\n<review>\\nThe product functions as intended. While some users may find it great, others might have different experiences. It appears to meet basic expectations, though individual preferences will vary. For a balanced perspective, potential buyers may want to consider both positive and negative reviews before making a decision.', sentiment='neutral'),\n",
       " GenericReview(review=\"This product performs as expected. It has some positive qualities but also room for improvement. While some users may find it great, others might have a more moderate experience. Overall, it's a functional item that meets basic needs without particularly standing out. Consider your specific requirements when deciding if this product is right for you.\", sentiment='neutral'),\n",
       " GenericReview(review='I had high hopes for this product, but I\\'m disappointed to say it fell short of expectations. Despite claims of being \"great,\" I found numerous issues that left me frustrated. The quality is subpar, and it doesn\\'t perform as advertised. Customer service was unhelpful when I tried to address my concerns. Overall, I can\\'t recommend this product and feel it\\'s a waste of money. Save yourself the hassle and look for better alternatives elsewhere.', sentiment='negative'),\n",
       " GenericReview(review=\"I had high hopes for this product, but unfortunately, it fell far short of my expectations. Despite claims of greatness, I found it to be mediocre at best. The quality was subpar, and it didn't perform nearly as well as advertised. I experienced several issues during use, and customer service was unhelpful when I reached out for support. Overall, I'm disappointed with my purchase and cannot recommend this product. It's definitely not worth the price, and there are much better alternatives available on the market. Save yourself the frustration and look elsewhere.\", sentiment='negative'),\n",
       " GenericReview(review='I had high hopes for this product, but unfortunately, it fell far short of my expectations. Despite claims of being \"great,\" I found it to be mediocre at best. The quality is subpar, and it doesn\\'t perform nearly as well as advertised. I experienced several issues during use, and customer support was unhelpful when I reached out. For the price, I expected much better. I cannot recommend this product and feel disappointed with my purchase. Save your money and look for alternatives.', sentiment='negative')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T10:14:50.848017Z",
     "start_time": "2025-01-30T10:14:50.841526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_sentiment(review: str, examples: list[GenericReview]) -> Literal[\"positive\", \"neutral\", \"negative\"]:\n",
    "    example_str = \"\\n\\n\".join([f\"Review_{i+1}: {r.review}\\nSentiment_{i+1}: {r.sentiment}\" for i, r in enumerate(examples)])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant that predicts the sentiment of a review.\n",
    "the sentiment of the review is one of following: positive, neutral, negative.\n",
    "the sentiment of the review should be enclosed in <sentiment> tags.\n",
    "\n",
    "<example>\n",
    "{example_str}\n",
    "</example>\n",
    "\n",
    "<review>\n",
    "{review}\n",
    "</review>\n",
    "\n",
    "What it is the sentiment of the review?\n",
    "\"\"\"\n",
    "\n",
    "    response = get_messages(prompt)\n",
    "    sentiment = re.search(r\"<sentiment>(.*?)</sentiment>\", response, RegexFlag.DOTALL).group(1).strip()\n",
    "    return sentiment"
   ],
   "id": "403af0b78d4de5be",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T10:17:07.374912Z",
     "start_time": "2025-01-30T10:16:43.436821Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install sentence-transformers",
   "id": "199cbe0d4851526b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\r\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/05/89/7eb147a37b7f31d3c815543df539d8b8d0425e93296c875cc87719d65232/sentence_transformers-3.4.1-py3-none-any.whl.metadata\r\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\r\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.41.0 from https://files.pythonhosted.org/packages/7b/9f/92d3091c44cb19add044064af1bf1345cd35fbb84d32a3690f912800a295/transformers-4.48.1-py3-none-any.whl.metadata\r\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.4/44.4 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting tqdm (from sentence-transformers)\r\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.7/57.7 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting torch>=1.11.0 (from sentence-transformers)\r\n",
      "  Obtaining dependency information for torch>=1.11.0 from https://files.pythonhosted.org/packages/b3/17/41f681b87290a1d2f1394f943e470f8b0b3c2987b7df8dc078d8831fce5b/torch-2.6.0-cp39-none-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading torch-2.6.0-cp39-none-macosx_11_0_arm64.whl.metadata (28 kB)\r\n",
      "Collecting scikit-learn (from sentence-transformers)\r\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/83/74/f64379a4ed5879d9db744fe37cfe1978c07c66684d2439c3060d19a536d8/scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl.metadata\r\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (31 kB)\r\n",
      "Collecting scipy (from sentence-transformers)\r\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/5c/c0/e71b94b20ccf9effb38d7147c0064c08c622309fd487b1b677771a97d18c/scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata\r\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.6/60.6 kB\u001B[0m \u001B[31m7.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting huggingface-hub>=0.20.0 (from sentence-transformers)\r\n",
      "  Obtaining dependency information for huggingface-hub>=0.20.0 from https://files.pythonhosted.org/packages/cc/ac/07f92291add9f425f40b3fd70a1d0c7117f6e1152599abc2bd7fda5b6abe/huggingface_hub-0.28.0-py3-none-any.whl.metadata\r\n",
      "  Downloading huggingface_hub-0.28.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting Pillow (from sentence-transformers)\r\n",
      "  Obtaining dependency information for Pillow from https://files.pythonhosted.org/packages/a6/62/c7b359e924dca274173b04922ac06aa63614f7e934d132f2fe1d852509aa/pillow-11.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading pillow-11.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.1 kB)\r\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/89/ec/00d68c4ddfedfe64159999e5f8a98fb8442729a63e2077eb9dcd89623d27/filelock-3.17.0-py3-none-any.whl.metadata\r\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/de/86/5486b0188d08aa643e127774a99bac51ffa6cf343e3deb0583956dca5b22/fsspec-2024.12.0-py3-none-any.whl.metadata\r\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\r\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl.metadata\r\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\r\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\r\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\r\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/7a/d1/598de10b17fdafc452d11f7dada11c3be4e379a8671393e4e3da3c4070df/regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.5/40.5 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for tokenizers<0.22,>=0.21 from https://files.pythonhosted.org/packages/22/7a/88e58bb297c22633ed1c9d16029316e5b5ac5ee44012164c2edede599a5e/tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\r\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/24/84/e9d3ff57ae50dd0028f301c9ee064e5087fe8b00e55696677a0413c377a7/safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\r\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\r\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\r\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\r\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\r\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m275.9/275.9 kB\u001B[0m \u001B[31m20.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.28.0-py3-none-any.whl (464 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m464.1/464.1 kB\u001B[0m \u001B[31m23.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading torch-2.6.0-cp39-none-macosx_11_0_arm64.whl (66.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.5/66.5 MB\u001B[0m \u001B[31m38.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m46.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.7/9.7 MB\u001B[0m \u001B[31m53.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pillow-11.1.0-cp39-cp39-macosx_11_0_arm64.whl (3.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m45.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.1/11.1 MB\u001B[0m \u001B[31m53.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.3/30.3 MB\u001B[0m \u001B[31m47.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m183.9/183.9 kB\u001B[0m \u001B[31m18.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m301.8/301.8 kB\u001B[0m \u001B[31m31.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m284.6/284.6 kB\u001B[0m \u001B[31m36.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl (408 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m408.9/408.9 kB\u001B[0m \u001B[31m29.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.6/2.6 MB\u001B[0m \u001B[31m51.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m48.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m40.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: mpmath, tqdm, threadpoolctl, sympy, scipy, safetensors, regex, Pillow, networkx, joblib, fsspec, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\r\n",
      "Successfully installed Pillow-11.1.0 filelock-3.17.0 fsspec-2024.12.0 huggingface-hub-0.28.0 joblib-1.4.2 mpmath-1.3.0 networkx-3.2.1 regex-2024.11.6 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.13.1 sentence-transformers-3.4.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 tqdm-4.67.1 transformers-4.48.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T10:36:16.924153Z",
     "start_time": "2025-01-30T10:36:14.014363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embedding(review: str) -> list[float]:\n",
    "    return model.encode(review)\n",
    "\n",
    "\n",
    "sentences = [\n",
    "    \"I love this product!\",\n",
    "    \"I live in a city full of bananas!\",\n",
    "    \"The product is great!\",\n",
    "    \"The product is terrible!\",\n",
    "    \"Baskets are full of bananas!\",\n",
    "]\n",
    "\n",
    "embedding = get_embedding(sentences)\n",
    "\n",
    "pairwise = model.similarity(embedding, embedding)\n",
    "\n",
    "print(\"유사도 매트릭스:\")\n",
    "print(pairwise)\n",
    "print(\"\\n유사도 벡터:\")\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(i+1, len(sentences)):\n",
    "        print(f\"{sentences[i]}: {sentences[j]}: {pairwise[i, j]:.4f}\")\n"
   ],
   "id": "83f29a129e541e29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 매트릭스:\n",
      "tensor([[1.0000, 0.2286, 0.7937, 0.5736, 0.1795],\n",
      "        [0.2286, 1.0000, 0.2366, 0.2771, 0.6944],\n",
      "        [0.7937, 0.2366, 1.0000, 0.6872, 0.1704],\n",
      "        [0.5736, 0.2771, 0.6872, 1.0000, 0.2120],\n",
      "        [0.1795, 0.6944, 0.1704, 0.2120, 1.0000]])\n",
      "\n",
      "유사도 벡터:\n",
      "I love this product!: I live in a city full of bananas!: 0.2286\n",
      "I love this product!: The product is great!: 0.7937\n",
      "I love this product!: The product is terrible!: 0.5736\n",
      "I love this product!: Baskets are full of bananas!: 0.1795\n",
      "I live in a city full of bananas!: The product is great!: 0.2366\n",
      "I live in a city full of bananas!: The product is terrible!: 0.2771\n",
      "I live in a city full of bananas!: Baskets are full of bananas!: 0.6944\n",
      "The product is great!: The product is terrible!: 0.6872\n",
      "The product is great!: Baskets are full of bananas!: 0.1704\n",
      "The product is terrible!: Baskets are full of bananas!: 0.2120\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T10:46:29.371528Z",
     "start_time": "2025-01-30T10:46:29.349555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "def cosine_distance(a: list[float], b: list[float]) -> float:\n",
    "    return 1 - sum(ai * bi for ai, bi in zip(a, b)) / (math.sqrt(sum(ai**2 for ai in a)) * math.sqrt(sum(bi**2 for bi in b)))\n",
    "\n",
    "def embed_queries(queries: list[str], model: SentenceTransformer) -> list[tuple[str, list[float]]]:\n",
    "    return [\n",
    "        (query, model.encode(query).tolist())\n",
    "        for query in queries\n",
    "    ]"
   ],
   "id": "b35a8b372d0650c9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T10:49:00.636682Z",
     "start_time": "2025-01-30T10:48:55.313132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedded_queries = embed_queries(sentences, model)\n",
    "\n",
    "dist = cosine_distance(embedded_queries[0][1], embedded_queries[1][1])\n",
    "\n",
    "print(sentences[0], sentences[1], f\"유사도: {dist:.4f}\")"
   ],
   "id": "7f012f74e3d68a99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this product! I live in a city full of bananas! 유사도: 0.7714\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T10:58:25.674810Z",
     "start_time": "2025-01-30T10:58:25.276607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = [\n",
    "    {\"question\": \"What is the capital of France?\", \"answer\": \"Paris\"},\n",
    "    {\"question\": \"What is the capital of Germany?\", \"answer\": \"Berlin\"},\n",
    "    {\"question\": \"What is the best programming language?\", \"answer\": \"Java\"},\n",
    "    {\"question\": \"What is the capital of Italy?\", \"answer\": \"Rome\"},\n",
    "]\n",
    "\n",
    "query = \"What is the capital of Korea?\"\n",
    "\n",
    "embeddings = embed_queries([example[\"question\"] for example in examples] + [query], model)\n"
   ],
   "id": "4f8bb78ed110aa47",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:08:03.781312Z",
     "start_time": "2025-01-30T11:08:03.772350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def knn(\n",
    "        embedded_queries: list[tuple[str, list[float]]],\n",
    "        query_embedding: list[float],\n",
    "        examples: list[dict[str, str]],\n",
    "        k: int = 3,\n",
    ") -> list[tuple[str, float]]:\n",
    "    distances = [\n",
    "        (cosine_distance(query_embedding, embed), query, examples[i][\"answer\"])\n",
    "        for i, (query, embed) in enumerate(embedded_queries)\n",
    "    ]\n",
    "\n",
    "    return sorted(distances, key=lambda x: x[0])[:k]\n",
    "\n",
    "knn(embedded_queries=embeddings[:-1],\n",
    "    query_embedding=embeddings[-1][1],\n",
    "    examples=examples)"
   ],
   "id": "7433288fb4fd471c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4342349895687475, 'What is the capital of Germany?', 'Berlin'),\n",
       " (0.47199984447232124, 'What is the capital of Italy?', 'Rome'),\n",
       " (0.50319621473308, 'What is the capital of France?', 'Paris')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:13:31.855380Z",
     "start_time": "2025-01-30T11:13:31.844304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_examples(examples: list[tuple[str, float]]) -> str:\n",
    "    return \"\\n\\n\".join([f\"Question_{i+1}: {e[1]}\\nAnswer_{i+1}: {e[2]}\" for i, e in enumerate(examples)])\n",
    "\n",
    "format_examples(knn(embedded_queries=embeddings[:-1], query_embedding=embeddings[-1][1], examples=examples))"
   ],
   "id": "9cf4b9e3bd419c8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question_1: What is the capital of Germany?\\nAnswer_1: Berlin\\n\\nQuestion_2: What is the capital of Italy?\\nAnswer_2: Rome\\n\\nQuestion_3: What is the capital of France?\\nAnswer_3: Paris'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:30:47.371275Z",
     "start_time": "2025-01-30T11:30:44.851640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def knn_response(question: str, examples: list[dict[str, str]]) -> str:\n",
    "    embeddings = embed_queries([e[\"question\"] for e in examples] + [question], model)\n",
    "    k_closest = knn(embedded_queries=embeddings[:-1], query_embedding=embeddings[-1][1], examples=examples)\n",
    "    example_str = format_examples(k_closest)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant that generates a response based on the question and examples.\n",
    "    Below are examples of questions and answers within the examples tag.\n",
    "    Using the examples as a reference, generate a response based on the question.\n",
    "    Please answer the question contained in the question tag.\n",
    "\n",
    "    <examples>\n",
    "    {example_str}\n",
    "    </examples>\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_messages(prompt)\n",
    "    return response\n",
    "\n",
    "knn_response(\"What is the popular programming language in 2024\", examples)"
   ],
   "id": "d708e8a27efeec49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the examples provided and the current question, I'll generate a response in a similar format:\\n\\nPython\\n\\nWhile the examples don't directly address the popularity of programming languages in 2024, I've provided a concise answer that follows the pattern of the given examples. Python is widely considered one of the most popular programming languages in recent years and is likely to maintain its popularity in 2024 due to its versatility, ease of use, and strong presence in fields like data science, machine learning, and web development.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
